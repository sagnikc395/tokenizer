## tokenization

An implementation of the GPT BPE Tokenizer and
adding a improvement using the [SuperBPE Algorithm](https://arxiv.org/abs/2503.13423).

### Readings:

1. Paper that introduced byte level tokenization in context of LLMs -> [GPT-2 Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

2. Byte Pair Encoding Algorithm -> https://arxiv.org/abs/1508.07909

3. Tokenization free Transformers ->

   1. [MEGABYTE](https://arxiv.org/abs/2305.07185)

4.
